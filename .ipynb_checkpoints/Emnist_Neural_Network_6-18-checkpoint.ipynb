{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34fb3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Entered Function\n",
      "Cost is: 0.3783864266414258\n",
      "2\n",
      "Entered Function\n",
      "Cost is: 0.3783864266414258\n",
      "3\n",
      "Entered Function\n",
      "Cost is: 0.37821785972037214\n",
      "4\n",
      "Entered Function\n",
      "Cost is: 0.3775923803891706\n",
      "5\n",
      "Entered Function\n",
      "Cost is: 0.375859478555941\n",
      "6\n",
      "Entered Function\n",
      "Cost is: 0.3743547054720781\n",
      "7\n",
      "Entered Function\n",
      "Cost is: 0.3701720088103295\n",
      "8\n",
      "Entered Function\n",
      "Cost is: 0.36879024050251674\n",
      "9\n",
      "Entered Function\n",
      "Cost is: 0.3651056856385941\n",
      "10\n",
      "Entered Function\n",
      "Cost is: 0.35735867536770427\n",
      "11\n",
      "Entered Function\n",
      "Cost is: 0.34791461768179266\n",
      "12\n",
      "Entered Function\n",
      "Cost is: 0.3429849130027497\n",
      "13\n",
      "Entered Function\n",
      "Cost is: 0.34261157241100154\n",
      "14\n",
      "Entered Function\n",
      "Cost is: 0.3414860714948612\n",
      "15\n",
      "Entered Function\n",
      "Cost is: 0.3408922591861223\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.340892\n",
      "         Iterations: 5\n",
      "         Function evaluations: 14\n",
      "         Gradient evaluations: 14\n",
      "Hyp: [3.80585860e-04 1.32439793e-04 3.16413403e-03 1.65867597e-02\n",
      " 5.59915430e-04 6.10307357e-05 1.59472107e-03 2.38501218e-03\n",
      " 9.92725989e-01 1.73810371e-05]\n",
      "Curr Val: 0.0003805858602157981 at index 0\n",
      "Curr Val: 0.00013243979340628006 at index 1\n",
      "Curr Val: 0.0031641340305294248 at index 2\n",
      "New Max Val: 0.0031641340305294248\n",
      "Curr Val: 0.016586759733418742 at index 3\n",
      "New Max Val: 0.016586759733418742\n",
      "Curr Val: 0.0005599154300124569 at index 4\n",
      "Curr Val: 6.103073571055707e-05 at index 5\n",
      "Curr Val: 0.001594721068857355 at index 6\n",
      "Curr Val: 0.0023850121762443426 at index 7\n",
      "Curr Val: 0.9927259887467003 at index 8\n",
      "New Max Val: 0.9927259887467003\n",
      "Curr Val: 1.7381037130443233e-05 at index 9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize as sp\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "class Neural_Network():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num = 0\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "    def sigmoidGradient(self,z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "    def regularization(self, lamda, m):\n",
    "        lamda_val = lamda/(2.0*m)\n",
    "        theta1_sum = 0 \n",
    "        theta2_sum = 0\n",
    "        for j in range(len(self.Theta1)-1):\n",
    "            for k in range(self.Theta1[0].size-1):\n",
    "                theta1_sum += self.Theta1[j+1][k+1]*self.Theta1[j+1][k+1]\n",
    "        for j in range(len(self.Theta2)-1):\n",
    "            for k in range(self.Theta2[0].size-1):\n",
    "                theta2_sum += self.Theta2[j+1][k+1]*self.Theta2[j+1][k+1]\n",
    "        return lamda_val*(theta1_sum+theta2_sum)\n",
    "    \n",
    "    def calc_cost(self, y_vals, hyp, lamda, m): #hyp and y are both 10x1 vectors \n",
    "        cost = 0\n",
    "        for k in range(y_vals.size):\n",
    "            cost += -y_vals[k] * math.log(hyp[k]) - (1-y_vals[k])*math.log(1-hyp[k])\n",
    "        return cost\n",
    "    \n",
    "    def predict(self, weights, x_vals):\n",
    "            x_vals = np.hstack(([1],x_vals))\n",
    "            weights1 = weights[0]\n",
    "            weights2 = weights[1]\n",
    "            z2 = np.matmul(x_vals,weights1.T)\n",
    "            a2 = self.sigmoid(z2)\n",
    "            a2 = np.concatenate((np.array([1]), a2))\n",
    "            z3 = np.matmul(a2,weights2.T)\n",
    "            a3 = self.sigmoid(z3)\n",
    "            print(\"Hyp: \" + str(a3))\n",
    "            max_val = a3[0]\n",
    "            max_index = 0\n",
    "            for i in range(len(a3)):\n",
    "                print(\"Curr Val: \" + str(a3[i]) + \" at index \" + str(i))\n",
    "                if (a3[i] > max_val):\n",
    "                    max_val = a3[i]\n",
    "                    print(\"New Max Val: \" + str(max_val))\n",
    "                    max_index = i\n",
    "            prediction = max_index+1\n",
    "            if prediction == 10:\n",
    "                prediction = 0\n",
    "            return prediction\n",
    "    \n",
    "    def nnCostFunction(self, nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_reg):\n",
    "        self.Theta1 = np.reshape(nn_params[:hidden_layer_size*(input_layer_size+1)],(hidden_layer_size, input_layer_size+1))\n",
    "        self.Theta2 = np.reshape(nn_params[hidden_layer_size*(input_layer_size+1):], (num_labels, hidden_layer_size+1))\n",
    "        \n",
    "        m = len(X)\n",
    "        labels = y.flatten()\n",
    "        # set y to be matrix of size m x k\n",
    "        y = np.zeros((m,num_labels))\n",
    "        # for every label, convert it into vector of 0s and a 1 in the appropriate position\n",
    "        for i in range(m): #each row is new training sample\n",
    "            index = int(labels[i]-1)\n",
    "            y[i][index] = 1\n",
    "        J = 0;\n",
    "        Theta1_grad = np.zeros_like(self.Theta1)\n",
    "        Theta2_grad = np.zeros_like(self.Theta2)\n",
    "\n",
    "        # add column of ones as bias unit from input layer to second layer\n",
    "        X = np.hstack((np.ones((m,1)), X)) # = a1\n",
    "        \n",
    "        #Forward and Back prop: \n",
    "\n",
    "        bigDelta1 = 0\n",
    "        bigDelta2 = 0\n",
    "        cost_temp = 0\n",
    "\n",
    "        # for each training example\n",
    "        for t in range(m):\n",
    "\n",
    "            ## step 1: perform forward pass\n",
    "            # set lowercase x to the t-th row of X\n",
    "            x = X[t]\n",
    "            # note that uppercase X already included column of ones \n",
    "            # as bias unit from input layer to second layer, so no need to add it\n",
    "\n",
    "            # calculate second layer as sigmoid( z2 ) where z2 = Theta1 * a1\n",
    "            z2 = np.matmul(x,self.Theta1.T)\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            # add column of ones as bias unit from second layer to third layer\n",
    "            a2 = np.concatenate((np.array([1]), a2))\n",
    "            # calculate third layer as sigmoid (z3) where z3 = Theta2 * a2\n",
    "           # print(\"Theta: \" + str(self.Theta2))\n",
    "            z3 = np.matmul(a2,self.Theta2.T)\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            ## step 2: \n",
    "            delta3 = np.zeros((num_labels))\n",
    "\n",
    "            #subtract actual val in y from each hypothesized val in a3\n",
    "            y_vals = np.zeros((num_labels))\n",
    "            for k in range(num_labels): #for each of the 10 labels subtract\n",
    "                y_k = y[t][k]\n",
    "                y_vals[k] = y_k\n",
    "                delta3[k] = a3[k] - y_k\\\n",
    "\n",
    "            ## step 3: for the hidden layer l=2, set delta2 = Theta2' * delta3 .* sigmoidGradient(z2)\n",
    "            # note that we're skipping delta2_0 (=gradients of bias units, which we don't use here)\n",
    "            delta2 = np.matmul(self.Theta2[:,1:].T, delta3) * self.sigmoidGradient(z2)\n",
    "\n",
    "            ## step 4: accumulate gradient from this example\n",
    "            # accumulation\n",
    "            bigDelta1 += np.outer(delta2, x)\n",
    "            bigDelta2 += np.outer(delta3, a2)\n",
    "\n",
    "            cost_temp += self.calc_cost(y_vals, a3, lambda_reg, m)\n",
    "        term1 = (1/m)*cost_temp\n",
    "        term2 = self.regularization(lambda_reg, m)\n",
    "        J = term1 + term2\n",
    "        #print(\"Cost is: \" + str(J))\n",
    "        # step 5: obtain gradient for neural net cost function by dividing the accumulated gradients by m\n",
    "        Theta1_grad = bigDelta1 / m\n",
    "        Theta2_grad = bigDelta2 / m\n",
    "        \n",
    "\n",
    "        #% REGULARIZATION FOR GRADIENT\n",
    "        # only regularize for j >= 1, so skip the first column\n",
    "        Theta1_grad_unregularized = np.copy(Theta1_grad)\n",
    "        Theta2_grad_unregularized = np.copy(Theta2_grad)\n",
    "        Theta1_grad += (float(lambda_reg)/m)*self.Theta1\n",
    "        Theta2_grad += (float(lambda_reg)/m)*self.Theta2\n",
    "        Theta1_grad[:,0] = Theta1_grad_unregularized[:,0]\n",
    "        Theta2_grad[:,0] = Theta2_grad_unregularized[:,0]\n",
    "        flattened_grads = np.hstack((Theta1_grad.flatten(),Theta2_grad.flatten()))\n",
    "        \n",
    "        return J, flattened_grads\n",
    "        \n",
    "\n",
    "df = pd.read_csv(r'/Users/elliesuit/emnist/Emnist Data/Theta1.csv', header = None)\n",
    "df2 = pd.read_csv(r'/Users/elliesuit/emnist/Emnist Data/Theta2.csv', header = None)\n",
    "df3 = pd.read_csv(r'/Users/elliesuit/emnist/Emnist Data/X.csv', header = None)\n",
    "df4 = pd.read_csv(r'/Users/elliesuit/emnist/Emnist Data/Y.csv', header = None)\n",
    "theta1 = np.zeros([25,401])\n",
    "theta2 = np.zeros([10,26])\n",
    "x = np.zeros([5000,400])\n",
    "y = np.zeros([5000,1])\n",
    "index = 0 \n",
    "while (index < 25):\n",
    "    theta1[index] = df.iloc[index]\n",
    "    index+=1\n",
    "\n",
    "index = 0\n",
    "while(index<10):\n",
    "    theta2[index] = df2.iloc[index]\n",
    "    index+=1\n",
    "\n",
    "index = 0\n",
    "while(index<5000):\n",
    "    x[index] = df3.iloc[index]\n",
    "    index+=1\n",
    "ones = np.ones((5000,1))\n",
    "#x = np.hstack((ones, Xtemp)) #this is a1 (67) \n",
    "\n",
    "index = 0\n",
    "while (index<5000):\n",
    "    y[index] = df4.iloc[index]\n",
    "    index+=1\n",
    "\n",
    "nn_params = [theta1, theta2] \n",
    "flattened_params = np.hstack((theta1.flatten(),theta2.flatten()))\n",
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "lambda_val = 1 \n",
    "n = Neural_Network()\n",
    "n.nnCostFunction(flattened_params, input_layer_size, hidden_layer_size, num_labels, x, y, lambda_val)\n",
    "#Minimize:\n",
    "flat_theta1 = nn_params[0].flatten()\n",
    "flat_theta2 = nn_params[1].flatten()\n",
    "initial_weights = [flat_theta1, flat_theta2]\n",
    "nn_params = np.hstack((flat_theta1, flat_theta2)) \n",
    "func_args = (input_layer_size, hidden_layer_size, num_labels, x, y, lambda_val)\n",
    "result = sp.minimize(n.nnCostFunction, x0 = nn_params, args = func_args, method = 'cg', jac = True, options = {'disp': True, 'maxiter': 5})\n",
    "adjusted_weights = result.x\n",
    "theta1 = np.reshape(adjusted_weights[:hidden_layer_size*(input_layer_size+1)],(hidden_layer_size, input_layer_size+1))\n",
    "theta2 = np.reshape(adjusted_weights[hidden_layer_size*(input_layer_size+1):], (num_labels, hidden_layer_size+1))\n",
    "\n",
    "#Prediction: \n",
    "print(n.predict([theta1,theta2],x[4702]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ec935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32586142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
